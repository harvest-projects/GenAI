{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.9.0.post1-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.2.1-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.1-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-18.1.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.11-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.5.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.0-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.1.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.2.1-cp310-cp310-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.18.3-cp310-cp310-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached faiss_cpu-1.9.0.post1-cp310-cp310-win_amd64.whl (13.8 MB)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.11-cp310-cp310-win_amd64.whl (442 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading numpy-2.2.1-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 3.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 3.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.6/12.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.2/12.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.3/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.1/12.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.9 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.9/12.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 4.2 MB/s eta 0:00:00\n",
      "Using cached pyarrow-18.1.0-cp310-cp310-win_amd64.whl (25.1 MB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading safetensors-0.5.1-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Downloading pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.0/2.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.1 MB 5.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.1 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.1 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.1 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.0-cp310-cp310-win_amd64.whl (43.9 MB)\n",
      "   ---------------------------------------- 0.0/43.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/43.9 MB 5.6 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.8/43.9 MB 5.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.9/43.9 MB 5.1 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.7/43.9 MB 4.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.7/43.9 MB 4.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.8/43.9 MB 4.8 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.8/43.9 MB 4.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.9/43.9 MB 4.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 8.7/43.9 MB 4.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 9.7/43.9 MB 4.8 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.7/43.9 MB 4.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 11.8/43.9 MB 4.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/43.9 MB 4.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 13.4/43.9 MB 4.7 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 14.4/43.9 MB 4.7 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 15.2/43.9 MB 4.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 16.3/43.9 MB 4.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 17.0/43.9 MB 4.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 18.1/43.9 MB 4.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 18.9/43.9 MB 4.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 19.7/43.9 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 20.7/43.9 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 21.8/43.9 MB 4.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 22.5/43.9 MB 4.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 23.6/43.9 MB 4.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 24.4/43.9 MB 4.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 25.4/43.9 MB 4.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 26.2/43.9 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 27.3/43.9 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 27.8/43.9 MB 4.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 28.8/43.9 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 29.9/43.9 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 30.9/43.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 32.0/43.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 33.0/43.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 33.6/43.9 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 34.6/43.9 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 35.4/43.9 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.4/43.9 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.2/43.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 38.0/43.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 38.8/43.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 39.6/43.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.4/43.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.2/43.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.7/43.9 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.5/43.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.3/43.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.9/43.9 MB 4.4 MB/s eta 0:00:00\n",
      "Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.1-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached yarl-1.18.3-cp310-cp310-win_amd64.whl (90 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, urllib3, tzdata, tqdm, threadpoolctl, sympy, safetensors, regex, pyyaml, pyarrow, propcache, Pillow, numpy, networkx, multidict, MarkupSafe, joblib, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, scipy, requests, pandas, multiprocess, jinja2, faiss-cpu, aiosignal, torch, scikit-learn, huggingface-hub, aiohttp, tokenizers, transformers, datasets, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 attrs-24.3.0 certifi-2024.12.14 charset-normalizer-3.4.1 datasets-3.2.0 dill-0.3.8 faiss-cpu-1.9.0.post1 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.27.1 idna-3.10 jinja2-3.1.5 joblib-1.4.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 numpy-2.2.1 pandas-2.2.3 propcache-0.2.1 pyarrow-18.1.0 pytz-2024.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.1 scikit-learn-1.6.0 scipy-1.15.0 sentence-transformers-3.3.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.5.1 tqdm-4.67.1 transformers-4.47.1 tzdata-2024.2 urllib3-2.3.0 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "AWS Health provides improved visibility into planned lifecycle events\n",
    "\n",
    "Posted On: Nov 9, 2023\n",
    "\n",
    "AWS Health introduces new features to help you manage planned lifecycle events, such as Amazon EKS Kubernetes version end of standard support, Amazon RDS certificate rotations, and end of support for other open source software. AWS Health is the authoritative source of information about service events and scheduled changes affecting your AWS cloud resources.\n",
    "\n",
    "These new features provide timely visibility into upcoming planned lifecycle events, a standardized data format that allows you to prepare and take actions, as well as the ability to dynamically track the completion of required actions at the resource-level. AWS Health also provides organization-wide visibility into planned lifecycle events for teams that manage workloads across the company.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed the documents\n",
    "documents = [sample]  # Replace with your dataset\n",
    "embeddings = embedding_model.encode(documents)\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What does AWS Health do?\"\n",
    "query_embedding = embedding_model.encode([query])\n",
    "_, retrieved_docs = index.search(query_embedding, k=3)\n",
    "context = \" \".join([documents[i] for i in retrieved_docs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Health provides organization-wide visibility into planned lifecycle events for teams that manage workloads across\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load generative model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Prepare input\n",
    "input_text = f\"Context: {context} Query: {query}\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(**inputs)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query, model, tokenizer, retrieval_model, faiss_index, documents):\n",
    "    query_embedding = retrieval_model.encode([query])\n",
    "    _, retrieved_docs = faiss_index.search(query_embedding, k=3)\n",
    "    context = \" \".join([documents[i] for i in retrieved_docs[0]])\n",
    "\n",
    "    input_text = f\"Context: {context} Query: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def generate_response(query):\n",
    "    return rag_pipeline(query, model, tokenizer, retrieval_model, index, documents)\n",
    "\n",
    "\n",
    "gr.Interface(fn=generate_response, inputs=\"text\", outputs=\"text\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
