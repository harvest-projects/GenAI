{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in g:\\anaconda\\envs\\harvest\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in g:\\anaconda\\envs\\harvest\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in g:\\anaconda\\envs\\harvest\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in g:\\anaconda\\envs\\harvest\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in g:\\anaconda\\envs\\harvest\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: faiss-cpu in g:\\anaconda\\envs\\harvest\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in g:\\anaconda\\envs\\harvest\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: gradio in g:\\anaconda\\envs\\harvest\\lib\\site-packages (5.10.0)\n",
      "Requirement already satisfied: rouge-score in g:\\anaconda\\envs\\harvest\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: ipywidgets in g:\\anaconda\\envs\\harvest\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: beautifulsoup4 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: filelock in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: torch>=1.11.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from sentence-transformers) (2.5.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: Pillow in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.3 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: httpx>=0.24.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (3.10.14)\n",
      "Requirement already satisfied: pydantic>=2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (2.10.4)\n",
      "Requirement already satisfied: pydub in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.8.6)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from gradio-client==1.5.3->gradio) (14.1)\n",
      "Requirement already satisfied: absl-py in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: certifi in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: networkx in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: joblib in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in g:\\anaconda\\envs\\harvest\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets faiss-cpu sentence-transformers gradio rouge-score ipywidgets datasets beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import faiss\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Check if GPU is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92f592678534e24a2fe0168684ff0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b4c3e3fd564e3891583a6d9b6ec309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e98665f90744bc8bb71fa708be7cc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937d68100472477ebddf683529836227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2979906fa6fb4ba4a135132e67236f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3bea9563c74ab7a73fbfd7edd93119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9240c4dbc10e4f73a7eb8384f178999f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb502168f4042488d1912b8629e2a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba18d0f001e8420fb8467490ffbdbbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f702ec2aaeac49919fcfc0ed51414369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30aa4a0dd4f4b8fb7804a7d919260f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538c8e5a16934a37840b3264a929cdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e262b2e32ffd49cc8e4ac3c5a1be4e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97f7ff51194061a9d1f355327dcf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e453517c09ad4efaafa69157ee9f29ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef85cb594c1472198c9cd1dcd5cf47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c36fc698e347b1a5f9940ddcbea52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", cache_folder=\"models\")\n",
    "\n",
    "# Load generative model and tokenizer\n",
    "# or t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=\"models\")\n",
    "generative_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", cache_dir=\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'index': 0, 'data': '[\\'How much does it cost to be a pet sitter?\\', \\'<p>Starting out as a pet sitter and offering your services on PetBacker is free, and you can set your own rates. When you get a reservation, a 15-25% service fee is deducted from the total booking amount.</p>\\\\r\\\\n<p>PetBacker service fees are reduced in levels based on the number of jobs you have completed. For more information do refer to the <a href=\"/help-center/pet-service-providers/pet-service-provider-incentive-program\">PetBacker incentive program</a> for the benefits you will receive.</p>\\\\r\\\\n<p>Any pet sitter/host suspected of soliciting payment outside of PetBacker will be suspended without notice. <br />Example: <br />1. Requesting customers to revise a booking from many days/visits/walks to one<br />2. Promoting other platforms<br />3. Requesting customers contact you outside by visiting Facebook, Google search, Map or other social media<br />4. Exchange of contacts or meet up before booking but not closing the deal (Penalty of 40% of the Fees to remove your account restriction)<br />5. Giving customers an unreasonable low rate or discount as a deposit (e.g. USD$1 for a Booking to get contact or to deal outside)<br />6. Cancelling or getting cancelled for a hired booking without good reason<br />7. Subsequent bookings or extensions not made via the platform<br />8. Misleading customers that PetBacker charges fees without informing them the importance of Pet Insurance that PetBacker includes in the hope they will deal with you outside<br />9. Requesting for Cash payment outside the platform<br />10. Requesting customers to pay Hidden fees outside the platform</p>\\\\r\\\\n<p>To restore your service fees from:<br />- First time suspected mistake, 30% to 20%, complete 5 new bookings<br />- Second time suspected mistake, 30% to 20%, complete 10 new bookings.</p>\\\\r\\\\n<p>For the third suspected mistake onwards, you will not receive anymore broadcast job requests, only normal Direct job requests at 35% of the fees.</p>\\\\r\\\\n<p>To fully restore your account you also have the option to join the <a href=\"/help-center/sponsors\">Sponsor Program</a> for a yearly fee.</p>\\\\r\\\\n<p>&nbsp;</p>\\\\r\\\\n<p><strong>You might also be interested in</strong></p>\\\\r\\\\n<p><a href=\"/help-center/sponsors\">Why be a sponsor?</a></p>\\\\r\\\\n<p><a href=\"/help-center/pet-service-providers/what-are-the-service-fees\">Why PetBacker need the service fees?</a>&nbsp;</p>\\\\r\\\\n<p><a href=\"/help-center/pet-service-providers/pet-service-provider-incentive-program\">Pet Service Provider Incentive Program</a></p>\\\\r\\\\n<p><a href=\"/help-center/policies/terms-of-use\">What are the terms of use?</a></p>\\']'}\n",
      "{'Unnamed: 0': 1, 'index': 1, 'data': \"['What methods of payment does PetBacker accept?', '<p>The methods of payment vary by region. Some of the payment methods PetBacker accepts are direct bank in, and major credit cards, debit cards via Paypal.</p>']\"}\n",
      "{'Unnamed: 0': 2, 'index': 2, 'data': \"['How does PetBacker store credit card information?', '<p>PetBacker does not store any credit card information. All credit card processing is done via Paypal.</p>']\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from: https://huggingface.co/datasets/JLK-ptbk/faq\n",
    "faq_dataset = load_dataset(\"JLK-ptbk/faq\", cache_dir=\"datasets\", split=\"train\")\n",
    "\n",
    "# Inspect the first few examples\n",
    "for i in range(3):\n",
    "    print(faq_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faq': ['What methods of payment does PetBacker accept?', 'The methods of payment vary by region. Some of the payment methods PetBacker accepts are direct bank in, and major credit cards, debit cards via Paypal.']}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def parse_data(data_str: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parses a string representation of a list into an actual list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safely evaluate the string to a Python list\n",
    "        data_list = ast.literal_eval(data_str)\n",
    "        if isinstance(data_list, list):\n",
    "            return data_list\n",
    "        else:\n",
    "            return []\n",
    "    except (SyntaxError, ValueError):\n",
    "        # If parsing fails, attempt to extract strings using regex\n",
    "        return re.findall(r\"'(.*?)'\", data_str)\n",
    "\n",
    "def remove_html(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes HTML tags from a string.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "def clean_entry(data_str: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Cleans a single 'data' field entry.\n",
    "    \"\"\"\n",
    "    parsed_list = parse_data(data_str)\n",
    "    cleaned_list = []\n",
    "    for item in parsed_list:\n",
    "        # Remove HTML tags\n",
    "        clean_text = remove_html(item)\n",
    "        # Normalize whitespace\n",
    "        clean_text = ' '.join(clean_text.split())\n",
    "        # Filter out entries that are too short or incomplete\n",
    "        if len(clean_text) > 10 and not re.search(r'\\bStartin\\b', clean_text, re.IGNORECASE):\n",
    "            cleaned_list.append(clean_text)\n",
    "    return cleaned_list\n",
    "\n",
    "# Apply the cleaning function\n",
    "def apply_cleaning(example) -> dict:\n",
    "    cleaned = clean_entry(example['data'])\n",
    "    return {'faq': cleaned}\n",
    "\n",
    "cleaned_dataset = faq_dataset.map(apply_cleaning, remove_columns=['Unnamed: 0', 'index', 'data'])\n",
    "\n",
    "print(cleaned_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset into a list of dictionaries\n",
    "import pandas as pd\n",
    "faq_pairs = []\n",
    "faq_list = cleaned_dataset[\"faq\"]\n",
    "for i in range(0, len(faq_list), 2):\n",
    "    faq_pairs.append({\"question\": faq_list[i], \"answer\": faq_list[i + 1]})\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(faq_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 91\n"
     ]
    }
   ],
   "source": [
    "# Embed the documents\n",
    "answers = dataset['answer']\n",
    "embeddings = embedding_model.encode(dataset[\"answer\"])\n",
    "\n",
    "# Determine the dimensionality of the embeddings\n",
    "d = embeddings.shape[1]\n",
    "\n",
    "# Initialize the FAISS index\n",
    "index = faiss.IndexFlatL2(d)  # Using L2 distance; consider IndexHNSWFlat or others for larger datasets\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generative model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an AI assistant helping users with their queries about PetBacker services.\"\n",
    ")\n",
    "\n",
    "\n",
    "def rag_qa(question, top_k=1):\n",
    "    # Encode the question to find similar answers\n",
    "    question_embedding = embedding_model.encode([question], convert_to_tensor=False)\n",
    "    question_embedding = np.array(question_embedding).astype(\"float32\")\n",
    "\n",
    "    # Search for the top_k most similar answers\n",
    "    distances, indices = index.search(question_embedding, top_k)\n",
    "\n",
    "    # Retrieve the relevant contexts\n",
    "    retrieved_answers = [answers[idx] for idx in indices[0]]\n",
    "\n",
    "    # Prepare the input for the generator\n",
    "    # Incorporate the system prompt\n",
    "    print(retrieved_answers)\n",
    "    context = ' '.join(retrieved_answers[0])\n",
    "    input_text = f\"{system_prompt}\\nQuestion: {question}\\nContext: {context}\"\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer.encode(\n",
    "        input_text, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "    )\n",
    "\n",
    "    # Generate the answer\n",
    "    outputs = model.generate(inputs, max_length=150, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode the generated answer\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Do I have to offer my services exclusively for PetBacker', 'PetBacker is a community of pet lovers, and we welcome any pet lover from any platform, any where in the world. You can offer pet care services on PetBacker even if you are already offering your services on other platforms like Facebook or Instagram. You might be interested in What are the terms of use?']]\n",
      "Q: What is PetBacker?\n",
      "A: True\n"
     ]
    }
   ],
   "source": [
    "# Example question\n",
    "user_question = \"What payment options can I use on PetBacker?\"\n",
    "\n",
    "# Get the answer from RAG\n",
    "generated_answer = rag_qa(user_question)\n",
    "\n",
    "print(\"Q:\", user_question)\n",
    "print(\"A:\", generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG pipeline function\n",
    "def rag_pipeline(query, retrieval_model, faiss_index, documents):\n",
    "    query_embedding = retrieval_model.encode([query])\n",
    "    _, retrieved_indices = faiss_index.search(query_embedding, k=3)\n",
    "    context = \" \".join([documents[i] for i in retrieved_indices[0]])\n",
    "\n",
    "    input_text = f\"Context: {context} Query: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = generative_model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the RAG pipeline\n",
    "query = \"What is Hugging Face?\"\n",
    "response = rag_pipeline(query, embedding_model, index, documents)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Evaluate the RAG Model\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Reference response for evaluation\n",
    "reference = \"Hugging Face is a company creating open-source libraries.\"\n",
    "\n",
    "# Evaluation with ROUGE\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(response, reference)\n",
    "print(\"ROUGE scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model for multi-modal retrieval\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Example: Image retrieval logic\n",
    "# Assume \"image_features\" and \"text_features\" are pre-computed\n",
    "text_query = \"open-source libraries\"\n",
    "text_features = clip_model.get_text_features(clip_processor(text=[text_query], return_tensors=\"pt\"))\n",
    "\n",
    "# Multi-modal response: Extend to use image features if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def generate_response(query):\n",
    "    return rag_pipeline(query, model, tokenizer, embedding_model, index, documents)\n",
    "\n",
    "\n",
    "gr.Interface(fn=generate_response, inputs=\"text\", outputs=\"text\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
