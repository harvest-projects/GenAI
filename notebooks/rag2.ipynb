{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/not-lain/rag-chatbot-using-llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets sentence-transformers faiss-cpu accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "ST = SentenceTransformer(\"all-MiniLM-L6-v2\", cache_folder=\"models\")\n",
    "dataset = load_dataset(\"JLK-ptbk/faq\", cache_dir=\"datasets\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33552378293d471a9214c536eff8279b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/182 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c6b00c53f94f6e9180f34f89ed605f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['data', 'embeddings'],\n",
       "    num_rows: 182\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add embeddings to the dataset\n",
    "dataset = dataset.map(\n",
    "    lambda example: {\"embeddings\": ST.encode(example[\"data\"])},\n",
    "    remove_columns=[\"index\", \"Unnamed: 0\"],\n",
    ")\n",
    "\n",
    "# Add the index to the data\n",
    "dataset.add_faiss_index(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[\\'How do I rebook/extend booking with a sitter again?\\', \\'<p>Follow the steps to <strong>rebook/extend your ongoing booking</strong>:</p>\\\\r\\\\n<p>1) Navigate to the chat room with the booked sitter</p>\\\\r\\\\n<p>3) Tap on \"Rebook/Extend Booking\"</p><br />\\\\r\\\\n<p style=\" text-align: center; \"><img width=\"300px\" src=\"https://storage.googleapis.com/petbacker/images/faq/en/how-to-extend-booking/part-1.gif\" alt=\"rebook 1\" /></p>\\\\r\\\\n<br />\\\\r\\\\n<p>To <strong>rebook again</strong> your completed booking:</p>\\\\r\\\\n<p>1) Navigate to the chat room with the booked sitter</p>\\\\r\\\\n<p>3) Tap on \"Book Again\"</p><br />\\\\r\\\\n<p style=\" text-align: center; \"><img width=\"300px\" src=\"https://storage.googleapis.com/petbacker/images/faq/en/how-to-extend-booking/part-2.gif\" alt=\"rebook 2\" /></p>\\\\r\\\\n<br />\\\\r\\\\n<p>4) Fill in all required fields and submit your Request!</p><br />\\\\r\\\\n<p style=\" text-align: center; \"><img width=\"300px\" src=\"https://storage.googleapis.com/petbacker/images/faq/en/how-to-extend-booking/part-3.gif\" alt=\"rebook 3\" /></p>\\']',\n",
       " '[\\'Get more from PetBacker!\\', \\'Complete your 5th booking and get a 10% cashback of your 5th booking. It can be used on your future booking. You will get 10% cashback for every completed 5th bookings. \\\\r\\\\n\\\\r\\\\n<br><br/>\\\\r\\\\n\\\\r\\\\n<a href=\"petbacker://rebooking\">Click here to use your voucher!</a>\\\\r\\\\n\\']',\n",
       " '[\\'What is withdrawable and non-withdrawable balance?\\', \\'<p>Balance in your wallet can be withdraw to your preferred payout methods.</p>\\\\r\\\\n<p>&nbsp;</p>\\\\r\\\\n<p><strong>Withdrawable Balance</strong> - These are available balance in your wallet that are withdrawable, it includes funds from jobs, refunds as well as cancellations from bookings.</p>\\\\r\\\\n<p>&nbsp;</p>\\\\r\\\\n<p><strong>Non-Withdrawable Balance</strong> - These are balance in your wallet that are not available to be withdraw at the moment, it includes</p>\\\\r\\\\n<ul>\\\\r\\\\n<li>on-going bookings</li>\\\\r\\\\n<li>first booking without a review (a review is required for your first booking)</li>\\\\r\\\\n<li>bookings without reviews and are still within the 2 day dispute period</li>\\\\r\\\\n<li>held jobs that have been disputed</li>\\\\r\\\\n<li>held jobs from suspicious activities.</li>\\\\r\\\\n</ul>\\\\r\\\\n<p>&nbsp;</p>\\\\r\\\\n<p>*It may take up to 7 working days on first time withdrawal/payout to verify account details.</p>\\\\r\\\\n\\\\r\\\\n</br>\\\\r\\\\n<p><strong>You might be interested in</strong></p>\\\\r\\\\n<p><a href=\"/help-center/policies/terms-of-use\">What are the terms of use?</a></p>\\']']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query: str, k: int = 3):\n",
    "    \"\"\"a function that embeds a new query and returns the most probable results\"\"\"\n",
    "    embedded_query = ST.encode(query)  # embed new query\n",
    "    scores, retrieved_examples = dataset.get_nearest_examples(  # retrieve results\n",
    "        \"embeddings\",\n",
    "        embedded_query,  # compare our new embedded query with the dataset embeddings\n",
    "        k=k,  # get only top k results\n",
    "    )\n",
    "    return scores, retrieved_examples\n",
    "search(\"rebook\")[1]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"You are an assistant for answering questions.\n",
    "You are given the extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"I do not know.\" Don't make up an answer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolLM-135M-Instruct\", cache_dir=\"models\"\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolLM-135M-Instruct\", cache_dir=\"models\"\n",
    ").to(\"cuda\")\n",
    "terminators = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(prompt, retrieved_documents, k):\n",
    "    \"\"\"using the retrieved documents we will prompt the model to generate our responses\"\"\"\n",
    "    PROMPT = f\"Question:{prompt}\\nContext:\"\n",
    "    for idx in range(k):\n",
    "        PROMPT += f\"{retrieved_documents['data'][idx]}\\n\"\n",
    "    return PROMPT\n",
    "\n",
    "\n",
    "def generate(formatted_prompt):\n",
    "    formatted_prompt = formatted_prompt[:2000]  # to avoid GPU OOM\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": formatted_prompt},\n",
    "    ]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        inputs, max_new_tokens=50, temperature=0.5, top_p=0.9, do_sample=True, eos_token_id=terminators\n",
    "    )\n",
    "    response = outputs[0][inputs.shape[-1] :]\n",
    "    return tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "def rag_chatbot(prompt: str, k: int = 2):\n",
    "    scores, retrieved_documents = search(prompt, k)\n",
    "    formatted_prompt = format_prompt(prompt, retrieved_documents, k)\n",
    "    return generate(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant\\nHere\\'s an example of how you could answer the question:\\n\\n\"What is PetBackers?'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chatbot(\"What is Pet Backers?\", k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
