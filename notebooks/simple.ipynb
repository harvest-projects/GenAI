{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets faiss-cpu sentence-transformers gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "AWS Health provides improved visibility into planned lifecycle events\n",
    "\n",
    "Posted On: Nov 9, 2023\n",
    "\n",
    "AWS Health introduces new features to help you manage planned lifecycle events, such as Amazon EKS Kubernetes version end of standard support, Amazon RDS certificate rotations, and end of support for other open source software. AWS Health is the authoritative source of information about service events and scheduled changes affecting your AWS cloud resources.\n",
    "\n",
    "These new features provide timely visibility into upcoming planned lifecycle events, a standardized data format that allows you to prepare and take actions, as well as the ability to dynamically track the completion of required actions at the resource-level. AWS Health also provides organization-wide visibility into planned lifecycle events for teams that manage workloads across the company.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed the documents\n",
    "documents = [sample]  # Replace with your dataset\n",
    "embeddings = embedding_model.encode(documents)\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What does AWS Health do?\"\n",
    "query_embedding = embedding_model.encode([query])\n",
    "_, retrieved_docs = index.search(query_embedding, k=3)\n",
    "context = \" \".join([documents[i] for i in retrieved_docs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load generative model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Prepare input\n",
    "input_text = f\"Context: {context} Query: {query}\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(**inputs)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query, model, tokenizer, retrieval_model, faiss_index, documents):\n",
    "    query_embedding = retrieval_model.encode([query])\n",
    "    _, retrieved_docs = faiss_index.search(query_embedding, k=3)\n",
    "    context = \" \".join([documents[i] for i in retrieved_docs[0]])\n",
    "\n",
    "    input_text = f\"Context: {context} Query: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def generate_response(query):\n",
    "    return rag_pipeline(query, model, tokenizer, embedding_model, index, documents)\n",
    "\n",
    "\n",
    "gr.Interface(fn=generate_response, inputs=\"text\", outputs=\"text\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harvest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
